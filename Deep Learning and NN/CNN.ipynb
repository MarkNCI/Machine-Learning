{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN",
      "provenance": [],
      "authorship_tag": "ABX9TyPTk2z2bVY5YpI7tTx5ZZly"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH2-NbfstlC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional Neural Network\n",
        "# Data that doesn't align into columns\n",
        "# Images, machine translation,sentence classification, sentiment analysis\n",
        "# Source data needs proper dimensions (e.g. width*height*colour channels)\n",
        "# Conv2D layer convulates a 2D layer\n",
        "# MaxPool2D layes reduce data by taking a max value in a block\n",
        "# Flattening will convert 2D to 1D to pass to hidden layers\n",
        "# Usually Conv2D -> MaxPooling2D -> Dropout -> Flatten -> Dense -> Dropout -> Softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nNzXrQw2ohO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN with MNIST\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWFtx-fk3ZD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "21c7239b-d162-4998-929a-5e812e697804"
      },
      "source": [
        "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91J9h4Xd3dz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unlike Keras example, we can use 28*28 pixel images as they are.\n",
        "# We're using 1*28*28 as it's greyscale. If colour, use 3 for red,green,blue\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  trainImages = mnist_train_images.reshape(mnist_train_images.shape[0],1,28,28)\n",
        "  testImages = mnist_test_images.reshape(mnist_test_images.shape[0],1,28,28)\n",
        "  inputShape = (1,28,28)\n",
        "else:\n",
        "  trainImages = mnist_train_images.reshape(mnist_train_images.shape[0],28,28,1)\n",
        "  testImages = mnist_test_images.reshape(mnist_test_images.shape[0],28,28,1)\n",
        "  inputShape = (28,28,1)\n",
        "\n",
        "trainImages = trainImages.astype('float32')\n",
        "testImages = testImages.astype('float32')\n",
        "trainImages /= 255\n",
        "testImages /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv6WfaPh5SoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert labels to one hot\n",
        "trainLabels = tf.keras.utils.to_categorical(mnist_train_labels,10)\n",
        "testLabels = tf.keras.utils.to_categorical(mnist_test_labels,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmcrAIol53sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9e4c014f-1c9f-4808-865f-9cd66fa05236"
      },
      "source": [
        "\n",
        "# Visualise training images\n",
        "def displayImage(number):\n",
        "  # Check one hot array of image label\n",
        "  print(trainLabels[number])\n",
        "  # Convert label bact to 0-9\n",
        "  label = trainLabels[number].argmax(axis=0)\n",
        "  # Reshape 1D tensor (768 pixels) into 28*28 image\n",
        "  image = trainImages[number].reshape([28,28])\n",
        "  # Show image\n",
        "  plt.title('Sample: %d Label: %d' % (number, label))\n",
        "  plt.imshow(image,cmap=plt.get_cmap('gray_r'))\n",
        "  plt.show()\n",
        "\n",
        "displayImage(600)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-VezprY6D0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "93a99a4b-172f-42a0-a521-239b546a4c63"
      },
      "source": [
        "# Build thr model\n",
        "model = Sequential()\n",
        "# 32 kernels size 3*3. Kernel is a filter used to extract features from an image\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=inputShape))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "# Reduce 2*2 pixel block to a single pixel, represents max pixel found\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "# Reduce neurons to prevent overfitting\n",
        "model.add(Dropout(0.25))\n",
        "# Flatten result to 1D to pass to final layer\n",
        "model.add(Flatten())\n",
        "# Hidden layer for learning\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Classify from 0-9 with softmax\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzXc77QO7NMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5dfnsfd9QxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d9ab4dd8-405e-49ed-8b5a-e8aa5b1e2fc3"
      },
      "source": [
        "model.fit(trainImages,trainLabels,batch_size=32,epochs=10,verbose=2,validation_data=(testImages,testLabels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 13s - loss: 0.1844 - accuracy: 0.9437 - val_loss: 0.0432 - val_accuracy: 0.9864\n",
            "Epoch 2/10\n",
            "1875/1875 - 13s - loss: 0.0795 - accuracy: 0.9766 - val_loss: 0.0422 - val_accuracy: 0.9866\n",
            "Epoch 3/10\n",
            "1875/1875 - 13s - loss: 0.0622 - accuracy: 0.9813 - val_loss: 0.0320 - val_accuracy: 0.9900\n",
            "Epoch 4/10\n",
            "1875/1875 - 13s - loss: 0.0476 - accuracy: 0.9860 - val_loss: 0.0256 - val_accuracy: 0.9918\n",
            "Epoch 5/10\n",
            "1875/1875 - 13s - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.0283 - val_accuracy: 0.9911\n",
            "Epoch 6/10\n",
            "1875/1875 - 13s - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0268 - val_accuracy: 0.9915\n",
            "Epoch 7/10\n",
            "1875/1875 - 13s - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
            "Epoch 8/10\n",
            "1875/1875 - 13s - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0315 - val_accuracy: 0.9905\n",
            "Epoch 9/10\n",
            "1875/1875 - 13s - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0376 - val_accuracy: 0.9905\n",
            "Epoch 10/10\n",
            "1875/1875 - 13s - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0287 - val_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8c0477b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbOijrGa9yYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d815b532-81e6-4334-85e4-c68165df5ec2"
      },
      "source": [
        "# Check the accuracy and loss\n",
        "accuracyScoring = model.evaluate(testImages,testLabels,verbose=0)\n",
        "print('Test Loss: ',accuracyScoring[0])\n",
        "print('Test Accuracy: ',accuracyScoring[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss:  0.028723398223519325\n",
            "Test Accuracy:  0.9918000102043152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L42hU-Yo-Uea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
