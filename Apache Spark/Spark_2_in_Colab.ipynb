{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark 2. in Colab",
      "provenance": [],
      "authorship_tag": "ABX9TyMbqIURx0chAOetl5eioMz6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "066HCor4HTR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c838b896-2aac-4291-e2e2-4bd4213fc630"
      },
      "source": [
        "# Installing Spark 2.4.6 with dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "print('Success1')\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "print('Success2')\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "print('Success3')\n",
        "!pip install -q findspark\n",
        "print('Success4')\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "print('Success5')\n",
        "import findspark\n",
        "findspark.init()\n",
        "print('Success6')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success1\n",
            "Success2\n",
            "Success3\n",
            "Success4\n",
            "Success5\n",
            "Success6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}