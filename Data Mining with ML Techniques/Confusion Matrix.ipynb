{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Confusion Matrix",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZWgN2iRwhemZZIown/J2l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9sxjz1g7h8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## What is a Confusion Matrix?\n",
        "# It's a way of measuring the performance of a model\n",
        "# A basic example would be similar to a graph:\n",
        "# Actual Yes/No on the top axis, Predicted Yes/No left axis\n",
        "# Can also come as heat map, which I've done before for multi-class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El---60eYYSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Matrix Classifiers\n",
        "# Recall: True Positives/True Positives+False Negatives\n",
        "# Also called Sensitivity, True Positive Rate and Completeness\n",
        "# % of correct positives predicted\n",
        "# Good choice for false negatives. For example:Fraud Detection\n",
        "# A false negatives would be a fraudulent transaction that was missed!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHiHkUiSaLm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Precision\n",
        "# True Positives/True Positives+False Positive\n",
        "# Also called Correct Positives\n",
        "# Good choice for false positives. For example: medical screening, drug tests\n",
        "# Other include F1 Score, RMSE (Root Mean Squared Error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lken-ScdV44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "93ecc304-8bf4-4a0a-db3a-9bb1a2a02bc2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "actual = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0] \n",
        "predicted = [1, 0, 0, 1, 0, 0, 1, 1, 1, 0] \n",
        "results = confusion_matrix(actual, predicted) \n",
        "\n",
        "print('Confusion Matrix :')\n",
        "print(results) \n",
        "print('Accuracy Score :',accuracy_score(actual, predicted) )\n",
        "print('Report : ')\n",
        "print(classification_report(actual, predicted) )\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[4 2]\n",
            " [1 3]]\n",
            "Accuracy Score : 0.7\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73         6\n",
            "           1       0.60      0.75      0.67         4\n",
            "\n",
            "    accuracy                           0.70        10\n",
            "   macro avg       0.70      0.71      0.70        10\n",
            "weighted avg       0.72      0.70      0.70        10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPcZZdgTbxb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC Curve\n",
        "# Receiver Operating Characteristic Curve\n",
        "# Plots true positive rate (recall) vs false positive rate at various threshold settings\n",
        "# Pts above diagonal are good classifications, pts in  upper left being best\n",
        "# The more line is bent towards upper left the better"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0wLqpL5d6yQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AUC\n",
        "# Area Under Curve in ROC curve\n",
        "# Equal to probabilty that classifier will rank randomly chosen positive probabilty higher than a negative one\n",
        "# ROC AUC of 0.5 is useless, 1.0 is good\n",
        "# Usefull for comparing classifiers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrcfmLDYcdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Add code at some point\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}