{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Reinforcement Learning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfz5--_ryMrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reinforcement Learning ##\n",
        "# You have an agent that explores space (Think Pac-Man)\n",
        "# It learns the value of different state changes in different conditions\n",
        "# These values inform agent's future behaviour\n",
        "# When space explored = fast online performance\n",
        "\n",
        "## Q-Learning ##\n",
        "# Specific Reinforcement Learning implementation\n",
        "# Set of environmental states (s), possible actions in each state (a) and a value of each state/action (Q)\n",
        "# Pac-Man: s is wall/ghost etc., a is movement and Q is positive/negative value\n",
        "# Start of with Q values of 0, explore space.\n",
        "# Bad things (ghost eats you), reduce Q. Good things (eat ghost) increase Q\n",
        "# Discount factor: look beyond one step. s: previous state, s' is current state\n",
        "# Q(s,a) += discount*(reward(s,a)+max(Q(s'))-Q(s,a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bmxtNQ2yMrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Exploration problem (Can be called Markov decision process (MDP)) ##\n",
        "# What's the best way to explore all possible states\n",
        "# Simple option: For state s, choose action with highest Q. If tie, random choice\n",
        "# Can miss paths this way, so better to use a Epsilon Term\n",
        "# If a random no. < epsilon, use random choice vs following highest Q\n",
        "# Here exploration never stops but choosing epsilon can be tricky"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQVAH-ItyMr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "a136c6d0-4e0b-49d0-eaad-240ce7cc10bb"
      },
      "source": [
        "# Taxi Problem: Build self-driving taxi to pick up and drop off at fixed pts\n",
        "# Get there quickest while avoiding obstacles\n",
        "import gym,random\n",
        "\n",
        "random.seed(1234)\n",
        "streets = gym.make(\"Taxi-v3\").env\n",
        "streets.render()\n",
        "\n",
        "# R,G,B,Y = pick up/drop off locations\n",
        "# Blue = pick up passenger, Magenta= drop them off\n",
        "# | are obstacles, : are OK\n",
        "# 5x5 grid so 25 locations, 4 destinations. Passenger can be in taxi or at one pt (5 pts)\n",
        "# 25*4*5 = 500 states. Six possible actions: pickup, drop off and move North,South,East and West\n",
        "# Q-Learning awards 20pts for drop off, -1pt per step and illegal action -10pt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m:\u001b[43m \u001b[0m|\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrJC-jQEyMr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "97fa9b64-0233-43b9-c68c-57aa938a7cdf"
      },
      "source": [
        "# Initial state: taxi (Yellow) at (2,3), pickup at 2 and drop off at 0\n",
        "initialState = streets.encode(2,3,2,0)\n",
        "streets.s = initialState # street state\n",
        "streets.render()\n",
        "streets.P[initialState] # scoring"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[43m \u001b[0m: |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [(1.0, 368, -1, False)],\n",
              " 1: [(1.0, 168, -1, False)],\n",
              " 2: [(1.0, 288, -1, False)],\n",
              " 3: [(1.0, 248, -1, False)],\n",
              " 4: [(1.0, 268, -10, False)],\n",
              " 5: [(1.0, 268, -10, False)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnl8_xFIyMr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train 10k taxi runs, each has 10% chance of exploring (discount factor)\n",
        "import numpy as np\n",
        "\n",
        "q_table = np.zeros([streets.observation_space.n,streets.action_space.n])\n",
        "learningRate = 0\n",
        "discountFactor = 0.6\n",
        "exploration = 0.1\n",
        "epochs = 1\n",
        "\n",
        "# For each run, reset field. \n",
        "for run in range(epochs):\n",
        "    state = streets.reset()\n",
        "    finished = False\n",
        "    \n",
        "    # Draw random number between 0 +1\n",
        "    # If less than exploration choose random action\n",
        "    # Else highest Q\n",
        "    while not finished:\n",
        "        randomValue = random.uniform(0,1)\n",
        "        if(randomValue < exploration):\n",
        "            action = streets.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])\n",
        "            \n",
        "        nextState, scoring, finished, info = streets.step(action)\n",
        "        \n",
        "        # Q-Learning\n",
        "        previousQ = q_table[state,action]\n",
        "        nextMaxQ = np.max(q_table[nextState])\n",
        "        newQ = (1 -learningRate)*previousQ+learningRate*(scoring+discountFactor*nextMaxQ)\n",
        "        state = nextState"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFqWDZ4hyMr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Table of q_values to choose next best step\n",
        "q_table[initialState]\n",
        "## Issue with data load, nned to come back to it"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}